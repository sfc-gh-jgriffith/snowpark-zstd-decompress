{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Snowpark to implement ZSTD dictionary decompression\n",
    "Snowflake has compress and decompress function that support ZSTD, but it does not support a user-supplied dictionary file. This code demonstrates:\n",
    "1. Connecting to Snowflake using the Snowpark for Python connector.\n",
    "2. Creating fake data using the Faker library and creating a ZSTD dictionary file. \n",
    "3. Uploading that faked & compressed to a Snowflake table.\n",
    "4. Upload our dictionary file to a stage and create a Python UDF to decompress data using that file.\n",
    "5. Calling that Python UDF using ordinary SQL\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to Snowflake using the Snowpark for Python connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 12:30:39.685 INFO    snowflake.connector.connection: Snowflake Connector for Python Version: 2.7.12, Python Version: 3.8.15, Platform: macOS-10.16-x86_64-i386-64bit\n",
      "2023-02-27 12:30:39.686 INFO    snowflake.connector.connection: This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2023-02-27 12:30:39.686 INFO    snowflake.connector.connection: Setting use_openssl_only mode to False\n",
      "2023-02-27 12:30:40.722 INFO    snowflake.snowpark.session: Snowpark Session information: \n",
      "\"version\" : 1.1.0,\n",
      "\"python.version\" : 3.8.15,\n",
      "\"python.connector.version\" : 2.7.12,\n",
      "\"python.connector.session.id\" : 647878641524774,\n",
      "\"os.name\" : Darwin\n",
      "\n",
      "2023-02-27 12:30:40.728 INFO    snowflake.connector.cursor: query: [select current_warehouse() wh, current_database() db, current_schema() schema, c...]\n",
      "2023-02-27 12:30:40.912 INFO    snowflake.connector.cursor: query execution done\n",
      "2023-02-27 12:30:40.915 INFO    snowflake.connector.cursor: query: [SELECT  *  FROM (select current_warehouse() wh, current_database() db, current_s...]\n",
      "2023-02-27 12:30:41.071 INFO    snowflake.connector.cursor: query execution done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "|\"WH\"    |\"DB\"                     |\"SCHEMA\"  |\"V\"    |\n",
      "-------------------------------------------------------\n",
      "|XSMALL  |COMMODITIES_FORECASTING  |PUBLIC    |7.6.3  |\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import pandas_udf\n",
    "from snowflake.snowpark.types import PandasSeries\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "from faker import Faker\n",
    "import pyzstd\n",
    "\n",
    "from cachetools import cached\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import json \n",
    "with open(\".env/creds.json\") as f:\n",
    "   connection_parameters = json.load(f)\n",
    "\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "# test if we have a connection\n",
    "session.sql(\"select current_warehouse() wh, current_database() db, current_schema() schema, current_version() v\").show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create synthetic data and create a ZSTD dictionary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 10,000 fake address records, encoded as bytes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'Unit 0108 Box 7551\\nDPO AP 91592',\n",
       " b'47788 Morris Stream Suite 478\\nEast Danieltown, IA 32108',\n",
       " b'619 Brandy Union Suite 977\\nNorth Sherryton, AK 52339',\n",
       " b'Unit 9457 Box 0274\\nDPO AP 16416',\n",
       " b'2344 Amber Circles\\nWest Connie, IA 68497',\n",
       " b'61131 Patterson Parkway\\nWest Patrickfort, MT 48632',\n",
       " b'27795 Johnson Stream Suite 993\\nNorth Stephenmouth, NE 49642',\n",
       " b'9609 Sarah Camp Apt. 285\\nWest Christineside, ME 08302',\n",
       " b'481 Steven Bridge\\nEast Lauraborough, PW 03394',\n",
       " b'7981 Pugh Mountain\\nAmychester, MP 33537']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake = Faker()\n",
    "fake_addresses = [bytes(fake.address(), 'utf-8') for i in range(10000)]\n",
    "fake_addresses[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ZSTD dictionary file, compress fake addresses, and write compressed addresses to a Snowflake table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary\n",
    "zstd_dict = pyzstd.train_dict(fake_addresses, 100*1024)\n",
    "\n",
    "# write our dictionary to a file\n",
    "with open(\"zstd_address_dictionary.d\", \"wb\") as f:\n",
    "    f.write(zstd_dict.dict_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'(\\xb5/\\xfd#e-\\x80e\\x1f\\xad\\x00\\x00\\xe3\\x00\\x02\\xf8{_$\\xbb\\xedv\\x16\\x03\\xfc\\x80\\xbd\\xa4B(\\x84k\\x01',\n",
       " b'(\\xb5/\\xfd#e-\\x80e7\\xf5\\x00\\x00\\xd3\\xc0\\x01n\\x87\\xe9\\xfdq\\xef\\xd6\\x06\\xfc}\\x1cB\\xa8A\\x92\\xb4*\\xa4ul\\x18mJ\\x94\\xed\\x02\\x1d',\n",
       " b'(\\xb5/\\xfd#e-\\x80e4\\xfd\\x00\\x00\\x03\\x01\\x03\\x9f\\x89\\xfb2\\x1ayVL^t\\xfcq\\x04\\xfc\\x8a(\\x92\\x8d1\\xbd\\x8f\\xf6\\x80Q\\xab\\x16\\x98\\x1c',\n",
       " b'(\\xb5/\\xfd#e-\\x80e\\x1f\\xa5\\x00\\x00\\xa3\\x80\\x01|\\xca\\x87\\xd6\\xab\\x01\\x03\\xfc\\x08\\xb1V\\xdeR\\xe1-\\x02\\x8a',\n",
       " b'(\\xb5/\\xfd#e-\\x80e(\\xed\\x00\\x00#A\\x03\\xfd\\xea\\\\\\x98M\\xa9\\x80\\x0c\\x1e\\x98RM\\x0c\\x03\\xfcX\\xf6\\x06\\xe7k\\x8aT\\x10\\xa0Ol',\n",
       " b'(\\xb5/\\xfd#e-\\x80e2\\xcd\\x00\\x00\\xa3\\x80\\x01\\x98\\xec\\xba#\\xef8\\x04\\xfc\\xccW\\x88\\xaf(\\x135\\xee4\\x91\\tv\\xa1(',\n",
       " b'(\\xb5/\\xfd#e-\\x80e;\\xf5\\x00\\x00\\xe3\\x00\\x02\\xa8\\xfcZ\\x1f\\x9d\\xff\\xef\\xc6\\x05\\xfcA\\x83\\xf2\\x9e1\\xc2\\xc5\\x02\\xc1i\\xa8Z\\xfa\\xf2&\\xa1E',\n",
       " b'(\\xb5/\\xfd#e-\\x80e5\\xf5\\x00\\x00\\xe3\\x00\\x02h\\xe9V\\x1f\\xeb\\xf8\\xc6\\x1f\\x06\\xfc\\xb4\\xcc\\x06\\xc9\\x1d\\x04\\xb0\\x7f\\x9f\\x19\\xf91\\xbd,<Q\\x01',\n",
       " b'(\\xb5/\\xfd#e-\\x80e-\\xc5\\x00\\x00\\x93\\x80\\x01\\xfa\\x99V)$\\x1a\\x04\\xfc|X\\x00\\x9e\\x8d:\\x02\\xab|iPr]',\n",
       " b\"(\\xb5/\\xfd#e-\\x80e'\\xe5\\x00\\x003\\x81\\x03\\x9d\\x9bY$\\x1c\\x1e\\x98\\x952\\\\H\\xea\\xfc;\\x02\\xc0\\xb2\\x1d\\xdb\\x813ac+\\x03\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_fake_addresses = [pyzstd.compress(i, zstd_dict=zstd_dict) for i in fake_addresses]\n",
    "compressed_fake_addresses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 12:30:42.570 INFO    snowflake.connector.cursor: query: [SELECT NULL :: BINARY AS \"COMRESSED_ADDRESS\"]\n",
      "2023-02-27 12:30:42.758 INFO    snowflake.connector.cursor: query execution done\n",
      "2023-02-27 12:30:42.761 INFO    snowflake.connector.cursor: query: [CREATE  OR  REPLACE  SCOPED TEMPORARY  TABLE SNOWPARK_TEMP_TABLE_4BSYBF7MW5(\"COM...]\n",
      "2023-02-27 12:30:43.009 INFO    snowflake.connector.cursor: query execution done\n",
      "2023-02-27 12:30:43.109 INFO    snowflake.connector.cursor: query: [INSERT  INTO SNOWPARK_TEMP_TABLE_4BSYBF7MW5(\"COMRESSED_ADDRESS\") VALUES (?)]\n",
      "2023-02-27 12:30:45.636 INFO    snowflake.connector.cursor: query execution done\n",
      "2023-02-27 12:30:45.640 INFO    snowflake.connector.cursor: query: [CREATE  OR  REPLACE    TABLE  compressed_addresses AS  SELECT  *  FROM ( SELECT ...]\n",
      "2023-02-27 12:30:46.852 INFO    snowflake.connector.cursor: query execution done\n",
      "2023-02-27 12:30:46.853 INFO    snowflake.connector.cursor: query: [DROP  TABLE  If  EXISTS SNOWPARK_TEMP_TABLE_4BSYBF7MW5]\n",
      "2023-02-27 12:30:46.965 INFO    snowflake.connector.cursor: query execution done\n"
     ]
    }
   ],
   "source": [
    "# write our fake addresses to a Snowflake table\n",
    "sp_df = session.create_dataframe(compressed_fake_addresses, schema=[\"comressed_address\"])\n",
    "sp_df.write.mode('overwrite').save_as_table(\"compressed_addresses\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy decompression UDF for our data using the dictionary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload dictionary and create UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 12:30:46.999 INFO    snowflake.connector.cursor: query: [create stage if not exists zstd_decompress]\n",
      "2023-02-27 12:30:47.189 INFO    snowflake.connector.cursor: query execution done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(status='ZSTD_DECOMPRESS already exists, statement succeeded.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a stage to hold our dictionary file and UDF\n",
    "session.sql(\"\"\"create stage if not exists zstd_decompress\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 12:30:47.220 INFO    snowflake.connector.cursor: query: [PUT 'file://zstd_address_dictionary.d' '@zstd_decompress'  parallel = 4 source_c...]\n",
      "2023-02-27 12:30:47.390 INFO    snowflake.connector.cursor: query execution done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PutResult(source='zstd_address_dictionary.d', target='zstd_address_dictionary.d.gz', source_size=102400, target_size=44928, source_compression='NONE', target_compression='GZIP', status='UPLOADED', message='')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write our dictionary file to our stage\n",
    "# this is our dictionary for our Faker data. you'll want to use your own dictionary\n",
    "session.file.put(\"zstd_address_dictionary.d\", \"@zstd_decompress\", overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a UDF\n",
    "Our UDF loads our dictionary file from the stage and uses the pyzstd library to decompress a binary field and return a string. \n",
    "\n",
    "We use a pandas_udf with inputs and outputs of a Pandas series. This is a [Vectorized UDF](https://docs.snowflake.com/en/developer-guide/snowpark/python/creating-udfs#label-snowpark-python-udf-vectorized) which enables better performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 12:30:48.153 INFO    snowflake.connector.cursor: query: [ls '@zstd_decompress']\n",
      "2023-02-27 12:30:48.285 INFO    snowflake.connector.cursor: query execution done\n",
      "2023-02-27 12:30:48.286 INFO    snowflake.connector.cursor: query: [SELECT \"name\" FROM ( SELECT  *  FROM  TABLE ( RESULT_SCAN('01aa9db6-0000-fe81-00...]\n",
      "2023-02-27 12:30:48.635 INFO    snowflake.connector.cursor: query execution done\n",
      "2023-02-27 12:30:48.637 INFO    snowflake.connector.cursor: query: [SELECT  *  FROM information_schema.packages]\n",
      "2023-02-27 12:30:48.730 INFO    snowflake.connector.cursor: query execution done\n",
      "2023-02-27 12:30:48.733 INFO    snowflake.connector.cursor: query: [SELECT \"PACKAGE_NAME\", array_agg(\"VERSION\") AS \"ARRAY_AGG(VERSION)\" FROM ( SELEC...]\n",
      "2023-02-27 12:30:49.525 INFO    snowflake.connector.cursor: query execution done\n",
      "2023-02-27 12:30:49.527 WARNING snowflake.snowpark.session: The version of package pyzstd in the local environment is 0.15.4, which does not fit the criteria for the requirement pyzstd. Your UDF might not work when the package version is different between the server and your local environment\n",
      "2023-02-27 12:30:49.527 WARNING snowflake.snowpark.session: The version of package cachetools in the local environment is 5.3.0, which does not fit the criteria for the requirement cachetools. Your UDF might not work when the package version is different between the server and your local environment\n",
      "2023-02-27 12:30:49.532 INFO    snowflake.connector.cursor: query: [PUT 'file:///tmp/placeholder/udf_py_143628847.zip' '@zstd_decompress/address_dec...]\n",
      "2023-02-27 12:30:49.750 INFO    snowflake.connector.cursor: query execution done\n",
      "2023-02-27 12:30:49.892 INFO    snowflake.connector.cursor: query: [CREATE OR REPLACE FUNCTION address_decompress(arg1 BINARY) RETURNS STRING LANGUA...]\n",
      "2023-02-27 12:31:02.115 INFO    snowflake.connector.cursor: query execution done\n"
     ]
    }
   ],
   "source": [
    "@cached(cache={})\n",
    "def read_file(filename):\n",
    "       import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "       if import_dir:\n",
    "              with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "                     m = file.read()\n",
    "                     return m\n",
    "\n",
    "@pandas_udf(name=\"address_decompress\", \n",
    "     is_permanent=True,\n",
    "     stage_location=\"@zstd_decompress\",\n",
    "     imports=[\"@zstd_decompress/zstd_address_dictionary.d\"], \n",
    "     packages=[\"pyzstd\", \"cachetools\"],\n",
    "     replace=True\n",
    "     )\n",
    "def address_decompress(input_df:PandasSeries[bytes])-> PandasSeries[str]:\n",
    "    d = read_file(\"zstd_address_dictionary.d\") \n",
    "    zstd_dict = pyzstd.ZstdDict(d)\n",
    "    output_series = input_df.apply(lambda x: pyzstd.decompress(x, zstd_dict=zstd_dict).decode('utf-8'))\n",
    "    return output_series "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call our Python UDF using normal SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 12:31:02.153 INFO    snowflake.connector.cursor: query: [select COMRESSED_ADDRESS, address_decompress(COMRESSED_ADDRESS) from compressed_...]\n",
      "2023-02-27 12:31:03.029 INFO    snowflake.connector.cursor: query execution done\n",
      "2023-02-27 12:31:03.031 INFO    snowflake.connector.cursor: query: [SELECT  *  FROM (select COMRESSED_ADDRESS, address_decompress(COMRESSED_ADDRESS)...]\n",
      "2023-02-27 12:31:04.494 INFO    snowflake.connector.cursor: query execution done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------\n",
      "|\"COMRESSED_ADDRESS\"                                 |\"ADDRESS_DECOMPRESS(COMRESSED_ADDRESS)\"  |\n",
      "------------------------------------------------------------------------------------------------\n",
      "|bytearray(b'(\\xb5/\\xfd#e-\\x80e\\x1f\\xad\\x00\\x00\\...  |Unit 0108 Box 7551                       |\n",
      "|                                                    |DPO AP 91592                             |\n",
      "|bytearray(b'(\\xb5/\\xfd#e-\\x80e2\\xfd\\x00\\x00#\\x0...  |4336 Graham Wall Apt. 212                |\n",
      "|                                                    |New Donnaburgh, LA 63045                 |\n",
      "|bytearray(b'(\\xb5/\\xfd#e-\\x80e/\\xdd\\x00\\x00\\xb3...  |522 Pennington Squares                   |\n",
      "|                                                    |Port Katiefurt, MN 43940                 |\n",
      "|bytearray(b'(\\xb5/\\xfd#e-\\x80e9\\xf5\\x00\\x00\\xe3...  |6776 Andre Corner Suite 616              |\n",
      "|                                                    |New Jacquelinemouth, NC 82972            |\n",
      "|bytearray(b'(\\xb5/\\xfd#e-\\x80e$\\xcd\\x00\\x00\\xd3...  |045 Flores Ramp                          |\n",
      "|                                                    |Anthonyton, UT 80371                     |\n",
      "|bytearray(b'(\\xb5/\\xfd#e-\\x80e)\\xf5\\x00\\x00#A\\x...  |8683 Todd Road                           |\n",
      "|                                                    |South Yeseniaton, ID 65076               |\n",
      "|bytearray(b'(\\xb5/\\xfd#e-\\x80e\\x1b\\xad\\x00\\x00@...  |USNS Blackburn                           |\n",
      "|                                                    |FPO AP 38313                             |\n",
      "|bytearray(b'(\\xb5/\\xfd#e-\\x80e7\\xed\\x00\\x00\\x03...  |86490 Campbell Island Apt. 399           |\n",
      "|                                                    |East Keithbury, VI 68283                 |\n",
      "|bytearray(b'(\\xb5/\\xfd#e-\\x80e8\\xfd\\x00\\x00#\\x0...  |8013 Michelle Mill Apt. 162              |\n",
      "|                                                    |North Jillianhaven, NJ 79628             |\n",
      "|bytearray(b'(\\xb5/\\xfd#e-\\x80e%\\xcd\\x00\\x00\\xe3...  |838 Melissa Rue                          |\n",
      "|                                                    |West Joshua, MA 25803                    |\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.sql(\"select COMRESSED_ADDRESS, address_decompress(COMRESSED_ADDRESS) from compressed_addresses\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "037a306d4a5432b51e32292273bfc766bf72b17fb1e355c8eac3fa56f0951cc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
